ğŸ§© PART 1 â€” Title + One-line description

Paste this at the top ğŸ‘‡

# LeRobot PushT â€“ ACT Policy Evaluation

This repository contains training checkpoints, evaluation videos, and notes from running the ACT policy on the PushT environment using Hugging Face LeRobot.


ğŸ”¹ This tells what the repo is
ğŸ”¹ Clear, simple, no buzzwords

ğŸ§© PART 2 â€” What you actually did

Add this below ğŸ‘‡

## What This Project Demonstrates

- Offline training of an ACT (Action Chunking Transformer) policy
- Evaluation on the PushT-v0 manipulation environment
- CPU-based execution using WSL (Ubuntu)
- Video-based qualitative analysis of agent behavior


ğŸ”¹ Shows skills, not just results
ğŸ”¹ Anyone reading knows this was hands-on

ğŸ§© PART 3 â€” Repo structure (very important)

Add this ğŸ‘‡

## Repository Structure


lerobot-pusht/
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ 000100/
â”‚       â””â”€â”€ pretrained_model/
â”‚
â”œâ”€â”€ results/
â”‚   â””â”€â”€ eval_videos/
â”‚       â”œâ”€â”€ eval_episode_0.mp4
â”‚       â”œâ”€â”€ eval_episode_1.mp4
â”‚       â””â”€â”€ eval_episode_2.mp4
â”‚
â”œâ”€â”€ notes/
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


ğŸ”¹ Reviewers LOVE this
ğŸ”¹ Makes your repo readable in 5 seconds

ğŸ§© PART 4 â€” Training details (simple, honest)

Add this ğŸ‘‡

## Training Details

- Environment: PushT-v0
- Policy: ACT
- Backbone: ResNet-18 (ImageNet pretrained)
- Training steps: 100 (demo run)
- Device: CPU
- Dataset: lerobot/pusht


âš ï¸ Saying â€œdemo runâ€ is GOOD â€” it shows honesty and awareness.

ğŸ§© PART 5 â€” Evaluation results

Add this ğŸ‘‡

## Evaluation

- Episodes evaluated: 3
- Success rate: 0%
- Evaluation time: ~2.5 seconds per episode
- Outputs include rollout videos and reward metrics

Note: Low success is expected due to very limited training steps. The goal of this project is to demonstrate the full training â†’ evaluation â†’ visualization pipeline.


ğŸ”¥ This line is important:

â€œdemonstrate the full pipelineâ€

Thatâ€™s exactly what you achieved.

ğŸ§© PART 6 â€” How to reproduce (optional but powerful)

Add this ğŸ‘‡

## How to Reproduce

Training:

python src/lerobot/scripts/lerobot_train.py \
  --env.type pusht \
  --policy.type act \
  --dataset.repo_id lerobot/pusht \
  --policy.repo_id local/pusht-test \
  --steps 100


```markdown
Evaluation:

python src/lerobot/scripts/lerobot_eval.py \
  --env.type pusht \
  --policy.type act \
  --policy.pretrained_path checkpoints/000100/pretrained_model \
  --eval.n_episodes 3 \
  --eval.batch_size 3 \
  --env.render_mode rgb_array

```

ğŸ”¹ Shows **reproducibility**  
ğŸ”¹ Huge plus for interviews / reviewers

---

## ğŸ§© PART 7 â€” Closing (short & mature)

Add this ğŸ‘‡

```markdown
## Notes

This project focuses on understanding policy behavior through evaluation videos rather than achieving high task success. It serves as a foundation for further experimentation with longer training runs and GPU acceleration.
```

---

## âœ… Save & exit nano

Press:
```
CTRL + O â†’ Enter
CTRL + X
```

---

## ğŸŒŸ What you now have

- A **real ML project README**
- Not flashy, but **serious**
- Perfect for GitHub, college, or future internships

---

### Next step options (pick one):

4ï¸âƒ£ Create GitHub repo under **santhanuss** using `gh`  
5ï¸âƒ£ Improve results (longer training / smaller model)  
6ï¸âƒ£ Explain the videos *frame-by-frame* in simple language  

Just reply with the number ğŸ˜¼

give me a eady readme file

Got you ğŸ˜¼ğŸ’™
Here is a READY-TO-USE README.md â€” clean, simple, and professional.
You can copy-paste this entire thing directly into your README.md.

# LeRobot PushT â€“ ACT Policy Evaluation

This repository documents a complete training and evaluation pipeline using the ACT (Action Chunking Transformer) policy on the PushT environment with Hugging Face LeRobot.

The focus of this project is understanding policy behavior through evaluation videos rather than achieving high task success.

---

## What This Project Shows

- Offline training of an ACT policy on PushT-v0
- End-to-end workflow: training â†’ checkpointing â†’ evaluation
- CPU-based execution using WSL (Ubuntu)
- Qualitative analysis using rollout videos

---

## Repository Structure



lerobot-pusht/
â”œâ”€â”€ checkpoints/
â”‚ â””â”€â”€ 000100/
â”‚ â””â”€â”€ pretrained_model/
â”‚
â”œâ”€â”€ results/
â”‚ â””â”€â”€ eval_videos/
â”‚ â”œâ”€â”€ eval_episode_0.mp4
â”‚ â”œâ”€â”€ eval_episode_1.mp4
â”‚ â””â”€â”€ eval_episode_2.mp4
â”‚
â”œâ”€â”€ notes/
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## Training Configuration

- Environment: PushT-v0
- Policy: ACT (Action Chunking Transformer)
- Vision Backbone: ResNet-18 (ImageNet pretrained)
- Dataset: lerobot/pusht
- Training steps: 100 (demo run)
- Device: CPU

---

## Evaluation Results

- Episodes evaluated: 3
- Success rate: 0%
- Average episode time: ~2.5 seconds
- Outputs:
  - Rollout videos (`.mp4`)
  - Reward and timing metrics

Low success is expected due to the very limited number of training steps.  
The goal is to validate the full evaluation and visualization pipeline.

---

## How to Reproduce

### Training

```bash
python src/lerobot/scripts/lerobot_train.py \
  --env.type pusht \
  --policy.type act \
  --dataset.repo_id lerobot/pusht \
  --policy.repo_id local/pusht-test \
  --steps 100

Evaluation
python src/lerobot/scripts/lerobot_eval.py \
  --env.type pusht \
  --policy.type act \
  --policy.pretrained_path checkpoints/000100/pretrained_model \
  --eval.n_episodes 3 \
  --eval.batch_size 3 \
  --env.render_mode rgb_array

Notes

This repository is intended as a learning and experimentation project.
Future improvements include longer training runs, GPU acceleration, and policy tuning for higher success rates.


---
# LeRobot PushT â€“ ACT Policy Evaluation

This repository contains training checkpoints, evaluation videos, and notes from running the ACT policy on the PushT environment using Hugging Face LeRobot.

## What This Project Demonstrates

- Offline training of an ACT (Action Chunking Transformer) policy
- Evaluation on the PushT-v0 manipulation environment
- CPU-based execution using WSL (Ubuntu)
- Video-based qualitative analysis of agent behavior
## Repository Structurelerobot-pusht/
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ 000100/
â”‚       â””â”€â”€ pretrained_model/
â”‚
â”œâ”€â”€ results/
â”‚   â””â”€â”€ eval_videos/
â”‚       â”œâ”€â”€ eval_episode_0.mp4
â”‚       â”œâ”€â”€ eval_episode_1.mp4
â”‚       â””â”€â”€ eval_episode_2.mp4
â”‚
â”œâ”€â”€ notes/
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

## Training Details

- Environment: PushT-v0
- Policy: ACT
- Backbone: ResNet-18 (ImageNet pretrained)
- Training steps: 100 (demo run)
- Device: CPU
- Dataset: lerobot/pusht
## Evaluation

- Episodes evaluated: 3
- Success rate: 0%
- Evaluation time: ~2.5 seconds per episode
- Outputs include rollout videos and reward metrics

Note: Low success is expected due to very limited training steps. The goal of this project is to demonstrate the full training â†’ evaluation â†’ visualization pipeline.
## How to Reproduce

Training:
python src/lerobot/scripts/lerobot_train.py \
  --env.type pusht \
  --policy.type act \
  --dataset.repo_id lerobot/pusht \
  --policy.repo_id local/pusht-test \
  --steps 100

```markdown
Evaluation:
python src/lerobot/scripts/lerobot_eval.py \
  --env.type pusht \
  --policy.type act \
  --policy.pretrained_path checkpoints/000100/pretrained_model \
  --eval.n_episodes 3 \
  --eval.batch_size 3 \
  --env.render_mode rgb_array
```

ğŸ”¹ Shows **reproducibility**  
ğŸ”¹ Huge plus for interviews / reviewers

---

## ğŸ§© PART 7 â€” Closing (short & mature)

Add this ğŸ‘‡

```markdown
## Notes

This project focuses on understanding policy behavior through evaluation videos rather than achieving high task success. It serves as a foundation for further experimentation with longer training runs and GPU acceleration.
```

---

## âœ… Save & exit nano

Press:
```
CTRL + O â†’ Enter
CTRL + X
```

---

## ğŸŒŸ What you now have

- A **real ML project README**
- Not flashy, but **serious**
- Perfect for GitHub, college, or future internships

---

### Next step options (pick one):

4ï¸âƒ£ Create GitHub repo under **santhanuss** using `gh`  
5ï¸âƒ£ Improve results (longer training / smaller model)  
6ï¸âƒ£ Explain the videos *frame-by-frame* in simple language  

Just reply with the number ğŸ˜¼
